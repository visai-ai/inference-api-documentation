"use strict";(self.webpackChunkvisai_inference_api_documentation=self.webpackChunkvisai_inference_api_documentation||[]).push([[3393],{67346:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>f,contentTitle:()=>u,default:()=>g,frontMatter:()=>m,metadata:()=>y,toc:()=>h});var o=a(87462),i=(a(67294),a(3905)),n=a(26389),s=a(94891),r=a(75190),l=a(47507),p=a(24310),d=a(63303),c=(a(75035),a(85162));const m={id:"uploading-file",title:"Asynchronous API - OCR Documentation",description:"",sidebar_label:"Uploading Files",hide_title:!0,hide_table_of_contents:!0,api:{tags:["asynchronous"],description:"",operationId:"asynOCRDocUploadingFileInfer",parameters:[{name:"X-API-Key",in:"header",description:"Your API key",required:!0,schema:{type:"string"}}],responses:{200:{description:"successful operation",content:{"application/json":{schema:{type:"object",properties:{job_id:{type:"string",description:"Job ID of the inference"}},title:"ApiResponse"}}}}},requestBody:{content:{"multipart/form-data":{schema:{type:"object",properties:{files:{type:"string",format:"binary",description:"Image or document file ('.jpg', '.jpeg', '.png', '.pdf', '.docx', and '.pptx')"},box_threshold:{type:"string",description:"Number between 0 to 1"}},required:["files"]}}}},method:"post",path:"/predict",servers:[{url:"https://longrun-api.visai.ai/v1/job/ocrdoc/predict/files",description:"Default server"}],securitySchemes:{"X-API-Key":{type:"apiKey",in:"header",name:"X-API-Key"}},fullURL:"https://longrun-api.visai.ai/v1/job/ocrdoc/predict/files",postman:{name:"OCR Inference",method:"POST",body:{mode:"formdata",formdata:[{key:"files",value:"file",type:"file"}]}}},sidebar_class_name:"post api-method",custom_edit_url:null},u=void 0,y={unversionedId:"ai-marketplace/ocr-documentation/asynchronous-api/uploading-file",id:"ai-marketplace/ocr-documentation/asynchronous-api/uploading-file",title:"Asynchronous API - OCR Documentation",description:"",source:"@site/docs/ai-marketplace/ocr-documentation/asynchronous-api/uploading-file.api.mdx",sourceDirName:"ai-marketplace/ocr-documentation/asynchronous-api",slug:"/ai-marketplace/ocr-documentation/asynchronous-api/uploading-file",permalink:"/inference-api-documentation/docs/ai-marketplace/ocr-documentation/asynchronous-api/uploading-file",draft:!1,editUrl:null,tags:[],version:"current",frontMatter:{id:"uploading-file",title:"Asynchronous API - OCR Documentation",description:"",sidebar_label:"Uploading Files",hide_title:!0,hide_table_of_contents:!0,api:{tags:["asynchronous"],description:"",operationId:"asynOCRDocUploadingFileInfer",parameters:[{name:"X-API-Key",in:"header",description:"Your API key",required:!0,schema:{type:"string"}}],responses:{200:{description:"successful operation",content:{"application/json":{schema:{type:"object",properties:{job_id:{type:"string",description:"Job ID of the inference"}},title:"ApiResponse"}}}}},requestBody:{content:{"multipart/form-data":{schema:{type:"object",properties:{files:{type:"string",format:"binary",description:"Image or document file ('.jpg', '.jpeg', '.png', '.pdf', '.docx', and '.pptx')"},box_threshold:{type:"string",description:"Number between 0 to 1"}},required:["files"]}}}},method:"post",path:"/predict",servers:[{url:"https://longrun-api.visai.ai/v1/job/ocrdoc/predict/files",description:"Default server"}],securitySchemes:{"X-API-Key":{type:"apiKey",in:"header",name:"X-API-Key"}},fullURL:"https://longrun-api.visai.ai/v1/job/ocrdoc/predict/files",postman:{name:"OCR Inference",method:"POST",body:{mode:"formdata",formdata:[{key:"files",value:"file",type:"file"}]}}},sidebar_class_name:"post api-method",custom_edit_url:null},sidebar:"aiMarketplaceSidebar",previous:{title:"Asynchronous API",permalink:"/inference-api-documentation/docs/ai-marketplace/ocr-documentation/asynchronous"},next:{title:"Get job status by ID",permalink:"/inference-api-documentation/docs/ai-marketplace/ocr-documentation/asynchronous-api/get-job-status"}},f={},h=[{value:"Asynchronous - OCR Documentation API",id:"asynchronous---ocr-documentation-api",level:2}],k={toc:h};function g(e){let{components:t,...a}=e;return(0,i.kt)("wrapper",(0,o.Z)({},k,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"asynchronous---ocr-documentation-api"},"Asynchronous - OCR Documentation API"),(0,i.kt)("div",{style:{display:"flex",alignItems:"center",gap:"0.5rem",marginBottom:"1rem"}},(0,i.kt)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg"},(0,i.kt)("path",{d:"M21 3H3M18 13L12 7M12 7L6 13M12 7V21",stroke:"#475467",strokeWidth:"2",strokeLinecap:"round",strokeLinejoin:"round"})),(0,i.kt)("h2",{style:{marginBottom:"0"}},"Create inference by uploading file")),(0,i.kt)("div",{className:"custom-url-container"},(0,i.kt)("span",{className:"custom-method"},"POST"),(0,i.kt)("span",{className:"custom-url"},"https://longrun-api.visai.ai/v1/job/ocrdoc/predict/files")),(0,i.kt)("details",{style:{marginBottom:"1rem"},"data-collapsed":!1,open:!0},(0,i.kt)("summary",{style:{}},(0,i.kt)("strong",null,"Header")),(0,i.kt)("div",null,(0,i.kt)("ul",null,(0,i.kt)(r.Z,{className:"paramsItem",param:{name:"X-API-Key",in:"header",description:"Your API key",required:!0,schema:{type:"string"}},mdxType:"ParamsItem"})))),(0,i.kt)(s.Z,{mdxType:"MimeTabs"},(0,i.kt)(c.Z,{label:"multipart/form-data",value:"multipart/form-data-schema",mdxType:"TabItem"},(0,i.kt)("p",{style:{marginLeft:"1rem",marginBottom:"0px",fontWeight:500,fontSize:"12px"}},"form-data body"),(0,i.kt)("details",{style:{},"data-collapsed":!1,open:!0},(0,i.kt)("summary",{style:{textAlign:"left"}},(0,i.kt)("strong",null,"Request Body")),(0,i.kt)("div",{style:{textAlign:"left",marginLeft:"1rem"}}),(0,i.kt)("ul",{style:{marginLeft:"1rem"}},(0,i.kt)("li",null,(0,i.kt)("div",null,(0,i.kt)("strong",null,"files"),(0,i.kt)("span",{style:{opacity:"0.6"}}," File"),(0,i.kt)("span",{style:{color:"#FA383E",marginLeft:"0.25rem",fontWeight:"700"}},"required")),(0,i.kt)("p",{style:{marginTop:0}},"Image or document raw files in a form of multi-part form data using the key name ",(0,i.kt)("b",null,"files"),".")))),(0,i.kt)("details",{style:{marginBottom:"1rem"},"data-collapsed":!1,open:!0},(0,i.kt)("summary",{style:{}},(0,i.kt)("span",{style:{opacity:"0.6"}},"optional"),(0,i.kt)("p",{style:{fontSize:"14px",opacity:"0.6"}},"Send with the form of multi-part form data")),(0,i.kt)("div",null,(0,i.kt)("ul",null,(0,i.kt)(r.Z,{className:"paramsItem",param:{name:"box_threshold",in:"query",description:"Adjusting the box_threshold value, ranged between 0 to 1, affects the detection of text in documents.\nA lower value allows the model to detect more bounding boxes, while a higher value reduces detection sensitivity.\nIt is recommended to start with the default value of 0.4 and gradually increment the value by 0.1 until achieving the desired result for the document being used.\n(Number between 0 - 1)",required:!1,style:"form",schema:{type:"float",default:"0.4"}},mdxType:"ParamsItem"})))))),(0,i.kt)("div",null,(0,i.kt)(n.Z,{mdxType:"ApiTabs"},(0,i.kt)(c.Z,{label:"200",value:"200",mdxType:"TabItem"},(0,i.kt)("div",null,(0,i.kt)(s.Z,{schemaType:"response",mdxType:"MimeTabs"},(0,i.kt)(c.Z,{label:"application/json",value:"application/json",mdxType:"TabItem"},(0,i.kt)(d.Z,{mdxType:"SchemaTabs"},(0,i.kt)(c.Z,{label:"Schema",value:"Schema",mdxType:"TabItem"},(0,i.kt)("details",{style:{},"data-collapsed":!1,open:!0},(0,i.kt)("summary",{style:{}},(0,i.kt)("span",{style:{opacity:"0.6"}}," object")),(0,i.kt)("div",{style:{marginLeft:"1rem"}},(0,i.kt)(p.Z,{collapsible:!1,name:"job_id",required:!1,schemaName:"string",schema:{description:"ID of the inference job",title:"job_id"},mdxType:"SchemaItem"})))),(0,i.kt)(c.Z,{label:"Example (from schema)",value:"Example (from schema)",mdxType:"TabItem"},(0,i.kt)(l.Z,{responseExample:'{\n    "job_id": "<job-id>"\n}',language:"json",mdxType:"ResponseSamples"}))))))))))}g.isMDXComponent=!0}}]);